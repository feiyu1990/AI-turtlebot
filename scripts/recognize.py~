#!/usr/bin/env python

import roslib
roslib.load_manifest('sensor_msgs')
import rospy
import caffe
import numpy as np
import cv2
import sys
import App
from geometry_msgs.msg import Twist
from sensor_msgs.msg import PointCloud2
import sensor_msgs
from sensor_msgs.msg import Image as Imgmsg
from cv_bridge import CvBridge, CvBridgeError
from sklearn import linear_model, cluster, svm
import skimage.io
import cPickle
from Tkinter import *
from PIL import Image, ImageTk

##install these
import speech_recognition as sr
from pybrain.datasets            import ClassificationDataSet, SupervisedDataSet
from pybrain.utilities           import percentError
from pybrain.tools.shortcuts     import buildNetwork
from pybrain.supervised.trainers import BackpropTrainer
from pybrain.structure.modules   import SoftmaxLayer

import select, termios, tty, ImageFile, os.path, time

class Recognizer:
	def __init__(self, app):
		self.app = app
		self.currspeed = 0
		self.points = []
		self.MAXNUMCLASSES = 100
		self.onyourown = False
		#change directory to caffe
        caffe_root = os.environ['HOME']+"/caffe/"
		self.resourcespath = os.environ['HOME']+"/workspace/src/recognize/resources/"

		#caffe_dir = os.environ['HOME']+"/caffe/examples"
		##put caffe files in python bin
		#os.chdir(caffe_dir)
		
		#classes
		self.classes = ["cat", "eight ball", "bottle", "cube"]
	
		#setup classifier
		MODEL_FILE = 'imagenet/imagenet_deploy.prototxt'
        PRETRAINED = 'imagenet/caffe_reference_imagenet_model'
		self.net = caffe.Classifier(MODEL_FILE, PRETRAINED, mean_file=caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy', channel_swap=(2,1,0), input_scale=255)
		
        self.net.set_phase_test()
        self.net.set_mode_gpu()
		
		self.makedataset()

		self.NUMFEATURES = len(self.net.blobs['fc7'].data[4])

        #svm
		#self.svm = svm.SVC(probability=True)

		X = []
		y = []


		#classification output layer
		self.classdata = SupervisedDataSet(self.NUMFEATURES, len(self.MAXNUMCLASSES))
		self.nn = buildNetwork( self.NUMFEATURES, self.MAXNUMCLASSES, bias=True, outclass=SoftmaxLayer )
		self.output = BackpropTrainer(nn)
		try:
			self.newclassdata = cPickle.load(open(self.resourcespath + "NEWCLASSDATA.pkl", 'rb'))
		except:
			self.alldata = cPickle.load(open(self.resourcespath + "DATA.pkl", 'rb'))
			combineddata = []
			for noun in self.alldata:
				combineddata += noun
			self.X,self.Y = zip(*combineddata)

			self.data = SupervisedDataSet(self.NUMFEATURES, self.MAXNUMCLASSES)
			for x, y in zip(self.X,self.Y):
				yv = [0]*self.NUMFEATURES
				yv[y] = 1
				data.addSample(x, yv)
		self.output.trainOnDataset(self.isnewdata)
		#self.output.trainUntilConvergence()

		#learns what new class looks like
		self.isnewdata = SupervisedDataSet(len(self.MAXNUMCLASSES), 2)
		self.isnewnn = buildNetwork( len(self.X[0]), 2, len(self.classes), bias=True, outclass=SoftmaxLayer )
		self.isnew = BackpropTrainer(self.isnewnn, self.isnewdata)
		try:
			self.isnewdata = cPickle.load(open(self.resourcespath + "ISNEWDATA.pkl", 'rb'))
			self.isnew.trainOnDataset(self.isnewdata)


		#learns whether or not it should be confident with its choice of new or old class
		self.isconfidentdata = SupervisedDataSet(2, 2)
		self.isconfidentnn = buildNetwork( len(self.X[0]), 2, len(self.classes), bias=True, outclass=SoftmaxLayer )
		self.isconfident = BackpropTrainer(self.isnewnn, self.isconfidentdata)
		try:
			self.isconfidentdata = cPickle.load(open(self.resourcespath + "CONFIDENCEDATA.pkl", 'rb'))
			self.isconfident.trainonDataset(self.confidencedata)


		#self.lr.fit(X,y)		
		#self.svm.fit(X,y)
		#self.kmeans.fit(X,y)

		#print "\n\n\n----------TESTING--------\n\n\n"
		#test()

		self.bridge = CvBridge()		
		rospy.init_node('turtlebot_image')
        #self.pub = rospy.Publisher('~cmd_vel', Twist)
        sub1 = rospy.Subscriber("depth/points", PointCloud2, self.process)
        #sub2 = rospy.Subscriber("camera/rgb/image_color", Imgmsg, self.getPoints)
		#rospy.Rate(4)
		root.mainloop()
        rospy.spin()
		
	def predict(self, img):
		#stop subscriber
		del sub1
		if self.app.isquit():
			cPickle.dump(self.isnewdata, open(self.resourcespath + "ISNEWDATA.pkl", 'wb'))
			cPickle.dump(self.isconfidentdata, open(self.resourcespath + "CONFIDENCEDATA.pkl", 'wb'))
			cPickle.dump(self.newclassdata, open(self.resourcespath + "NEWCLASSDATA.pkl", 'wb'))
			sys.exit(1)

		try:
			cvimage = self.bridge.imgmsg_to_cv(img, "bgr8")
		except CvBridgeError, e:
	  		print e	
		cvtcvimg = cv2.cvtColor(np.array(cvimage), cv2.COLOR_BGR2RGB)
		#for GUI
		convertedimg = Image.fromarray(cvtcvimg)
		#for caffe
		result = skimage.img_as_float(cvtcvimg)  


		self.net.predict([result])
		features = self.net.blobs['fc7'].data[4]
		x = np.array(features)
		x.shape = (4096)

		results = self.output.activate(x)
		numchoice = [n for n in results if n == max(results)][0]
		choicevector = [0]*self.MAXNUMCLASSES; choicevector[numchoice] = 1
		textchoice = self.classes[numchoice]
		likelihood = results[numchoice]
		self.app.updateResults((textchoice, likelihood), convertedimg)

		if self.app.isCheckAll():
			correctclass = self.getReal("What is this?")
			classindex, new = self.checkClass(correctclass)
			if new: self.classes.append(correctclass)
			correctvector = [0]*self.NUMFEATURES; correctvector[classindex] = 1
			self.trainAllWithOne(x, correctvector, new)
		else:
			if not isconfident(isnewresults(results))):
				correctclass = self.getReal("I don't know. What is this?")
				classindex, new = self.checkClass(correctclass)
				if new: self.classes.append(correctclass)
				correctvector = [0]*self.NUMFEATURES; correctvector[classindex] = 1
				self.trainAllWithOne(x, correctvector, new)

			else if isnew(results):
				correctclass = self.getReal("I don't know. What is this?")
				classindex, new = self.checkClass(correctclass)
				if new: self.classes.append(correctclass)
				correctvector = [0]*self.NUMFEATURES; correctvector[classindex] = 1
				self.trainAllWithOne(x, correctvector, new)

			else:
				new = False
				self.trainAllWithOne(x, choicevector, new)

		#start up subscriber again
		sub1 = rospy.Subscriber("depth/points", PointCloud2, self.process)

	def isnew(results):
		isitnew = isnewresults(results)
		return True if isitnew[0] >= isitnew[1] else False

	def isnewresults(results):
		return self.isnew.activate(results)

	def isconfident(isnewresults):
		isitconfident = self.isconfident.activate(isnewresults)
		return True if isitconfident[0] >= isitconfident[1] else False

	def process(self, points):
		#use velocity smoother
		pointsarr = np.fromstring(points.data, dtype=np.uint8)
		foundobjects = self.findobjects(pointsarr)
		if not foundobjects:
			self.moverandomly()
		else:
			for shape in objects:
				while not iscentered(shape, pointsarr):
					self.centerobject(shape, pointsarr)
				stop()
				self.sub2 = rospy.Subscriber("camera/rgb/image_color", Imgmsg, self.predict)

	def trainAllWithOne(self, X, trainvector, new):
		self.output.addSample(X, trainvector)
		self.output.trainOne(X, trainvector)

		isnewcorr = [1,0] if new else [0,1]; 
		self.isnewdata.addSample(results, isnewcorr)
		self.isnew.trainOne(results, isnewcorr)

		isconfidentcorr = [1,0] if (isnew(results) and new) or (not isnew(results) and not new) else [0,1]
		self.isconfidentdata.addSample(isnewresults(results), isconfidentcorr)
		self.isconfident.trainOne(isnewresults(results), isconfidentcorr)

	def getReal(self, string):
		correctclass = self.app.promptUser(string).replace("_", " ").replace("  ", " ")
			if correctclass[0] == " ":
				correctclass = correctclass[1:]
			if correctclass[-1] == " ":
				correctclass = correctclass[: -1]
			return correctclass

	def checkClass(self, correctclass):
		if correctclass in self.classes:		
			return ([i for i in range(len(self.classes)) if self.classes[i] == correctclass][0], False)
		else:
			return (len(self.classes), True)

	def findobjects(self, points):
		sumofdiffs = 0
		cntr = 0
		for i in range(1, len(points)-1):
			for j in range(1, len(points[i])-1):
					cntr += 4
					sumofdiffs += abs(points[i][j]-points[i+1][j])
					sumofdiffs += abs(points[i][j]-points[i-1][j])
					sumofdiffs += abs(points[i][j]-points[i][j+1])
					sumofdiffs += abs(points[i][j]-points[i][j-1])

		avgdepth = np.sum(points)/len(points)
		avgdiff = sumofdiffs/cntr

		objects = []

		for i in range(1, points-1):
			for j in range(1, points[i]-1):
				if avgdiff < max([points[i][j]-points[i+1][j],points[i][j]-points[i-1][j], points[i][j]-points[i][j+1], points[i][j]-points[i][j-1]]) and avgdepth > points[i][j]:
					#maxdropoff = max([points[i][j]-points[i+1][j],points[i][j]-points[i-1][j], points[i][j]-points[i][j+1], points[i][j]-points[i][j-1]])
					maxpoint = [i,j]
					center = self.bfs(maxpoint, points)
					objects.append(center)
		if len(objects)>0 return objects ? False

	def iscentered(self, point, points):
		center = (len(points[0]), len(points))
		change = (center[0]-shape[0], center[1]-shape[1])
		if change < (5,5):
			return True
		return False

	def stop():
		twist = Twist()
		#
		self.pub.publish(twist)

	def bfs(self, start, points):
		objectpoints = []
		stack = [points[start[0]][start[1]]]
		while len(stack) > 0:
			point = stack[-1]
			del stack[-1]
			objectpoints.append(point)
			neighbors = [[point[0]+1, point[1]], [point[0]+1, point[1]], [point[0], point[1]+1], [point[0], point[1]-1]]
			for neighbor in neighbors:
				if neighbor not in objectpoints and neighbor not in stack:
					if points[point[0]][point[1]] - points[neighbor[0]][neighbor[1]] < avgdiff:
						stack.append(neighbor)
			x, y = zip(*objectpoints)
			avgx = sum(x)/len(x)
			avgy = sum(y)/len(y)
			sump = 0
			for point in objectpoints:
				sump += points[point[0]][point[1]]
			avgz = sump/len(objectpoints)
			center = (avgx, avgy, avgz)
			return center

	def centerobject(self, shape, points):
		preferreddist = 90
		center = (len(points[0]), len(points))
		change = (center[0]-shape[0], center[1]-shape[1], preferreddist-shape[2])
		twist = Twist()
		#
		self.pub.publish(twist)


	def makedataset(self):
		#run images through caffe
		if not os.path.isfile(self.resourcespath + "DATA.pkl"):
			print "\n\n\n-----------------Serializing Images------------\n\n\n"	
			n = 10
			alldata = []
			
			#just to make sure it's working
			cntr = 0
			for folder in os.listdir(self.resourcespath + "data"):
				for img in os.listdir(self.resourcespath+"data/"+folder):
					cntr += 1
	
			#pickling through images 
			for folder in os.listdir(self.resourcespath + "data"):
				classes.append(folder[folder.index(".")+1:])
				classdata = []
				
				for img in os.listdir(self.resourcespath+"data/"+folder):	
        	                        print "Images left:", cntr
					cntr -= 1
					caffeimg = caffe.io.load_image(self.resourcespath+"data/"+folder+"/"+img)
					self.net.predict([caffeimg])
					features = self.net.blobs['fc7'].data[4]
					valuefeatures = []
					for feature in features:
						valuefeatures.append(float(feature))
					classdata.append((np.array(valuefeatures), int(folder[0])))
				alldata.append(classdata)
			cPickle.dump(alldata, open(self.resourcespath + "DATA.pkl", 'wb'))
	
	def test(self):
		totalscntr = [0] * len(self.classes)
		correctcntr = [0] * len(self.classes)
		#split each class' data into n parts
		n = 10
		for i in range(n):
			piccntr = 0
			testset = [[],[]]
			trainset = [[],[]]
        	        for noun in self.alldata:
        	        	partlen = int(len(noun)/n)
				testing = zip(*[noun[j] for j in range(i*partlen, (i+1)*partlen)])
				training = zip(*[k for k in noun if k not in testset])
				testset[0] += testing[0]
				testset[1] += testing[1]
				trainset[0] += training[0]
				trainset[1] += training[1]
			self.lr.fit(trainset[0], trainset[1])
			testsetX = np.array(testset[0])
			testsetX.shape = (len(testset[0]), 4096)
			outputvector = self.lr.predict(testsetX)
			for y in range(len(outputvector)):
				totalscntr[testset[1][y]] += 1
				print outputvector[y], " == ", testset[1][y]
				if outputvector[y] == testset[1][y]:
					correctcntr[testset[1][y]] += 1
		print str(correctcntr), str(totalscntr), str(sum(correctcntr)), str(sum(totalscntr))
		for i in range(len(totalscntr)):
			print "\n" + str(classes[i]) + ": Accuracy rate: " + str(correctcntr[i]/totalscntr[i]*100)+"%"
		sumcorrect = sum(correctcntr)
		sumtotals = sum(totalscntr)
		print  "\n\n" + "TOTAL: Accuracy rate: " + str((sumcorrect/sumtotals)*100)+"%"
	
if __name__ == "__main__":
	root = Tk()
	app = App(root)
	node = Recognizer(app)

